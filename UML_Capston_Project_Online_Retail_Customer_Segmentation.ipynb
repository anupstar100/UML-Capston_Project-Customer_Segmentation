{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "UML Capston Project - Online Retail Customer Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anupstar100/UML-Capston_Project-Customer_Segmentation/blob/main/UML_Capston_Project_Online_Retail_Customer_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Extraction/identification of major topics & themes discussed in news articles. </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### In this project, your task is to identify major customer segments on a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b>Attribute Information: </b>\n",
        "\n",
        "* ### InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
        "* ### StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n",
        "* ### Description: Product (item) name. Nominal.\n",
        "* ### Quantity: The quantities of each product (item) per transaction. Numeric.\n",
        "* ### InvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.\n",
        "* ### UnitPrice: Unit price. Numeric, Product price per unit in sterling.\n",
        "* ### CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
        "* ### Country: Country name. Nominal, the name of the country where each customer resides."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MOUNTING THE DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1jFnmGTfB4o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTING THE REQUIRED LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "iO6m-F-bB9QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING OUR DATA\n",
        "df = pd.read_csv('/content/drive/MyDrive/Capston Project/Online Retail Customer Segmentation/Online Retail (1).csv', encoding = \"ISO-8859-1\")"
      ],
      "metadata": {
        "id": "yCh9kk56Cxxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Glimpses of our data"
      ],
      "metadata": {
        "id": "3rHo6EBGDOIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FIRST FIVE ROWS\n",
        "df.head()"
      ],
      "metadata": {
        "id": "iPJwPKeyC-nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LAST FIVE ROWS\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "xyoq0JQrDXOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RANDOM FIVE ROWS\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "fzDB3zTlDfE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING A COPY OF OUR DATA\n",
        "df_copy = df.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "KOA2kiKe2DFC",
        "outputId": "3de636b1-1477-46e0-f657-30ec334bea7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-21ad0f358c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# CREATING A COPY OF OUR DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Information"
      ],
      "metadata": {
        "id": "eCkqSjSnEAfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "kFrPjk6TEW4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Z0oFE_dgDjQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "1. There are 8 columns with 5,41,909 rows of data.\n",
        "2. There are 5 categorical columns and 3 numerical columns. "
      ],
      "metadata": {
        "id": "6f4Gv7Y8EHPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "WYYZ10VjEFtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "IqLDPbQbFI-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for duplicate values\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "jq-lcF1sE5Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the duplicates\n",
        "df.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "wpK8on_DFcJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "8qOu-eTHGJKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "1. There are 5,268 duplicate rows.\n",
        "2. Shape of data before dropping the duplicates ---> (541909, 8)\n",
        "3. Shape of data after dropping the duplicates ---> (536641, 8)"
      ],
      "metadata": {
        "id": "yvNNi5DKGMpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NUMBER OF UNIQUE VALUES IN EAH COLUMN\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "-fbgc2jxGLno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECKING FOR NULL VALUES\n",
        "pd.DataFrame({'Columns' : df.columns,\n",
        "              'Toatl Nos of Null values' : df.isna().sum(),\n",
        "              '% of null values' : round(df.isna().mean() * 100,2)}).reset_index().drop(['index'], axis = 1)"
      ],
      "metadata": {
        "id": "qe_w1j3rHcis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "1. There are 1454 null values (0.27%) in `Description` columns.\n",
        "2. There are 135037 null values (25.16%) in `CustomerID` columns."
      ],
      "metadata": {
        "id": "l5HChQ52I526"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if InvoiceNo for Null Customer ID exist in cases where Customer ID is present for filling CustomerID Nulls\n",
        "df[df['CustomerID'] == 'NaN']"
      ],
      "metadata": {
        "id": "stf-OH8LIJfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "* No such cases present as empty dataframe is returned."
      ],
      "metadata": {
        "id": "Xa2S_k5LKPOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING A LIST OF UNIQUE INVOICES WHERE CUSTOMER ID IS NULL\n",
        "null_id_invoices = df[df.CustomerID.isna()]['InvoiceNo'].drop_duplicates().tolist()\n",
        "print('Invoices count with null Customer ID:  ', len(null_id_invoices))"
      ],
      "metadata": {
        "id": "Ta6Qf0j4KO8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK IF INVOICE NUMBER IN NULL CUSTOMER ID DF EXIST IN NON - NULL CUSTOMER ID DF\n",
        "df[~df['CustomerID'].isna()][df['InvoiceNo'].isin(null_id_invoices)]"
      ],
      "metadata": {
        "id": "JxWo8exJJpEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the customer ID's are missing, I assume these orders were not made by the customers already in the data set because those customers already have ID's. I also don't want to assign these orders to those customers because this would alter the insights I draw from the data. Instead of dropping the null CustomerID values which amounts to ~25% of data, let's assign those rows a unique customer ID per order using InvoiceNo. This will act as a new customer for each unique order."
      ],
      "metadata": {
        "id": "KFVvNjWkMpjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK IF INVOICE NUMBER HAS UNIQUE MAPPING WITH CUSTOMER ID SO THAT\n",
        "# EACH INVOICE NUMBER CORRESPONDING TO NULL CUSTOMER ID CAN BE ASSIGN A NEW CUSTOMER.\n",
        "df.groupby(['InvoiceNo'])['CustomerID'] \\\n",
        "                             .nunique() \\\n",
        "                             .reset_index(name='nunique') \\\n",
        "                             .sort_values(['nunique'], ascending=False) \\\n",
        "                             .head(10)"
      ],
      "metadata": {
        "id": "2zO7ZTWRLR0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "* On sorting, this data shows that each invoice related to maximum 1 customer."
      ],
      "metadata": {
        "id": "HYx9et4rN9jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING NewId COLUMN AND ASSIGNING TO InvoiceNo WHERE CustomerID IS NULL\n",
        "df['NewID'] = df['CustomerID']\n",
        "df.loc[df['CustomerID'].isnull(), ['NewID']] = df['InvoiceNo']\n",
        "\n",
        "# REMOVE ALL NON DIGIT CHARATERS FROM NewID COLUMNS\n",
        "# SINCE INVOICE CAN CONTAIN 'C' REFERRING TO CANCELLATIONS\n",
        "df['NewID'] = df['NewID'].astype(str).str.replace('\\D+', '')\n",
        "\n",
        "# CONVERT TO INTEGER\n",
        "df['NewID'] = pd.to_numeric(df['NewID'])\n",
        "\n",
        "# CHECK IF PRESENT CustomerIDs AND NewIDs HAVE ANY COMMON VALUES SINCE IT WOULD CREATE ALTER ACTUAL CUSTOMER INSIGHTS\n",
        "customer = df['CustomerID'].nunique()\n",
        "null_invoices = df[df.CustomerID.isnull()]['InvoiceNo'].nunique()\n",
        "new_ids = df['NewID'].nunique()\n",
        "print(\"Number of Customers:\", customer)\n",
        "print(\"Number of Orders where CustomerID in Null:\", null_invoices)\n",
        "print(\"Number of Customers + Number of Orders where CustomerID in Null:\", customer + null_invoices)\n",
        "print(\"Number of New ID's:\", new_ids)"
      ],
      "metadata": {
        "id": "0hfvJVIPNUbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Since both values equal, we know all the different orders that didn't have a customer ID got assigned unique NewID and no duplicates were created."
      ],
      "metadata": {
        "id": "SBNQQuxHJQNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RANGE OF InvoiceDate COLUMN\n",
        "print('Maximum Invoice Date: ', max(df['InvoiceDate']))\n",
        "print('Minimum Invoice Date: ', min(df['InvoiceDate']))"
      ],
      "metadata": {
        "id": "c9iY0bLzGuMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ADDING CANCELLATIONS COLUMN BASED ON DEFINITION THAT InvoiceNo START WITH 'C'\n",
        "df[\"cancellations\"] = np.where(df[\"InvoiceNo\"].str.startswith('C'), 1, 0)\n",
        "total_data = df[\"InvoiceNo\"].shape[0]\n",
        "cancelled_data = df[df.cancellations == 1].shape[0]\n",
        "print(\"Number of cancelled products data\", cancelled_data, cancelled_data*100/total_data, \"\\n\")\n",
        "\n",
        "print(df[df.cancellations == 1][\"Quantity\"].describe())\n",
        "\n",
        "# REMOVING CANCELLATIONS SINCE THEY HAVE NEGATIVE QUANTITIES AND MAKE ONLY ~2% OF DATA\n",
        "df = df[df.cancellations == 0]"
      ],
      "metadata": {
        "id": "U3SMBDafJzMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "F6oWRcekFNLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of Unit Price Variable"
      ],
      "metadata": {
        "id": "7aFGGffXFVIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MAXIMUM AND MINIMUM UNIT PRICE\n",
        "print(\"Minimum UnitPrice\", min(df[\"UnitPrice\"]))\n",
        "print(\"Maximum UnitPrice\", max(df[\"UnitPrice\"]))\n",
        "print('=== ' * 30 + '\\n')\n",
        "\n",
        "# DESCRIPTION OF UNIT PRICE COLUMN\n",
        "df[\"UnitPrice\"].describe()"
      ],
      "metadata": {
        "id": "XvHoVixZLEhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROWS WHERE UNIT PRICE IS LESS THAN ZERO OR NEGATIVE\n",
        "df[df.UnitPrice < 0]"
      ],
      "metadata": {
        "id": "AMqIr7mRLa6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVING THESE ROWS --- THEY ARE TOTAL 2 ROWS. SO IT WILL NOT IMPACT OUR DATA\n",
        "df = df[df['UnitPrice'] >= 0]"
      ],
      "metadata": {
        "id": "tSB0eAmlMyBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "FFOvJFHaGpXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Afetr removing the rows, the shape of our data becomws (527388, 10)"
      ],
      "metadata": {
        "id": "9IHcF-5sGwk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# % OF DATA WITH UNIT PRICE = 0\n",
        "print(\"% of data with Unit Price = 0: \", round(len(df[df.UnitPrice == 0]) * 100 / len(df),2),\"%\" )\n",
        "\n",
        "# NUMBER OF UNIQUE CUSTOMER WITH UNIT PRICE = 0\n",
        "print(\"Count of unique Customer ID where Unit Price = 0: \", df[df.UnitPrice == 0].CustomerID.nunique(), \"\\n\")\n",
        "\n",
        "# GETTING THE DATA WHERE UNIT PRICE IS ZERO BUT CUSTOMER ID IS NOT NULL\n",
        "print('=== ' * 25)\n",
        "df[df.UnitPrice == 0][~df.CustomerID.isnull()].head()"
      ],
      "metadata": {
        "id": "nzpTG-rZGvXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DROPPING ROWS WITH UNIT PRICE = 0\n",
        "df = df[df.UnitPrice > 0]\n",
        "df[\"UnitPrice\"].describe()"
      ],
      "metadata": {
        "id": "oet12lk7HLDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAXIMUM AND MUNIMUM QUANTITIES\n",
        "print(\"Minimum Quantity\", min(df[\"Quantity\"]))\n",
        "print(\"Maximum Quantity\", max(df[\"Quantity\"]))\n",
        "print('=== ' * 25 + '\\n')\n",
        "\n",
        "# STATISTICAL VALUES OF QUANTITY COLUMN\n",
        "df[\"Quantity\"].describe()"
      ],
      "metadata": {
        "id": "jWQErEluIFqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customer and total revenue split wrto country"
      ],
      "metadata": {
        "id": "U-4hv7yPwvTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADDING MONETARY INFORMATION BY CALCULATING TOTAL VALUE OF TRANSACTION\n",
        "df[\"Total_sales\"] = df[\"UnitPrice\"] * df[\"Quantity\"]\n",
        "\n",
        "# CREATING COUNTRY LEVEL GROUPING TO FIND UNIQUE CUSTOMER COUND AND %\n",
        "country_customer_df = df.groupby(\"Country\")[\"CustomerID\"].nunique().reset_index().rename(columns = \\\n",
        "                                                                                           {\"CustomerID\":\"count_CustomerID\"})\n",
        "country_customer_df[\"customer_%\"] = round(country_customer_df[\"count_CustomerID\"] * \\\n",
        "                                          100/country_customer_df[\"count_CustomerID\"].sum(),2)\n",
        "\n",
        "# CREATING COUNTRY LEVEL GROUPING TO FIND TOTAL REVENUE AND %\n",
        "country_df = df.groupby(\"Country\")[\"Total_sales\"].sum().reset_index()\n",
        "country_df[\"Total_sales%\"] = round(country_df[\"Total_sales\"] * 100 / country_df[\"Total_sales\"].sum(),2)"
      ],
      "metadata": {
        "id": "zbgxvJPlJaU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COUNTRY V/S CUSTOMER %\n",
        "country_customer_df = country_customer_df.sort_values(by = \"customer_%\", ascending = False)\n",
        "fig, ax = plt.subplots(figsize = (10, 4), dpi = 100)\n",
        "ax = sns.barplot(x = country_customer_df[\"Country\"], y = country_customer_df['customer_%'])\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation = 50, ha = \"right\")\n",
        "plt.show()\n",
        "\n",
        "# COUNTRY V/S TOTAL SALES %\n",
        "country_df = country_df.sort_values(by = \"Total_sales%\", ascending = False)\n",
        "fig, ax = plt.subplots(figsize = (10, 4), dpi = 100)\n",
        "ax = sns.barplot(x = country_df[\"Country\"], y = country_df['Total_sales%'])\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation = 50, ha = \"right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S_h1iPNFxzZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The United Kingdom not only has the most sales revenue, but also the most customers. Therefore, for the purpose of this analysis, I will be taking data corresponding to orders from the United Kingdom."
      ],
      "metadata": {
        "id": "4N4SGZkUzBAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING A UK DF\n",
        "uk_df = df[df.Country == \"United Kingdom\"]\n",
        "uk_df.info()"
      ],
      "metadata": {
        "id": "NvsIaYeHy0B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECKING MOST POPULAR PRODUCT IN UK\n",
        "uk_product = uk_df.groupby(['StockCode', 'Description'], as_index= False)['Quantity'].sum().sort_values(by = 'Quantity', ascending = False)\n",
        "uk_product.head(5)"
      ],
      "metadata": {
        "id": "Wp_SL6ejzX8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE UNIQUE NUMBER OF InvoiceNo PER CUSTOMER FOR ANALYZING UK \n",
        "groupby_customers = pd.DataFrame(uk_df.groupby('NewID')['InvoiceNo'].nunique())\n",
        "groupby_customers.describe()"
      ],
      "metadata": {
        "id": "KBA9kUlxzyRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE UNIQUE MBER OF PRODUCTS PER ORDER\n",
        "groupby_invoice = pd.DataFrame(uk_df.groupby('InvoiceNo')['StockCode'].nunique())\n",
        "groupby_invoice.columns = ['Number of products per Order']\n",
        "groupby_invoice.describe()"
      ],
      "metadata": {
        "id": "wfxyVwxpzyKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The average number of orders per customer is 1 and average number of products per Order is 15"
      ],
      "metadata": {
        "id": "9D16tu8N1Cte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RFM Analysis"
      ],
      "metadata": {
        "id": "IX1apAVH1ORO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFM is a data modeling method used to analyze customer value. It stands for Recency, Frequency and Monetary, which are just three metrics that describe what your customers did.\n",
        "\n",
        "* *Recency (R) of a customer* - Days since the last purchase.\n",
        "* *Frequency (F) of the bookings/turnover of a customer* - Number of purchases, e.g., in 6 months.\n",
        "* *Monetary (M)* - The total turnover of a customer: Sum of sales, e.g., in 6 months.\n",
        "\n",
        "For the analysis, we need to define a ‘analysis date’, which is the day on which we are conducting this analysis which I am taking as the next to last date in data and taking 1 year previous data from the selected date for recency calculation"
      ],
      "metadata": {
        "id": "pkrgsbIC1W6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERTING THE InvoiceDate COLUMN INTO DATETIME\n",
        "uk_df['InvoiceDate'] = pd.to_datetime(uk_df['InvoiceDate'])"
      ],
      "metadata": {
        "id": "O5THE9tL287S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING AN RFM ANALYSIS DF\n",
        "analysis_date = uk_df[\"InvoiceDate\"].max() + pd.DateOffset(1)\n",
        "print(\"RFM Analysis Date :\", analysis_date)\n",
        "\n",
        "# START DATE FOR OUR ANALYSIS DF\n",
        "start_date = analysis_date - pd.DateOffset(days = 365)\n",
        "print(\"Start Date when taking 1 year data for analysis :\", start_date)"
      ],
      "metadata": {
        "id": "qu3m0SMgzyAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uk_df.info()"
      ],
      "metadata": {
        "id": "TiJFAUzZzx5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LxIJp4CWzxx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hCYuzb_JzxrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tNSL_TJczxkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-NQYPcQfzxdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O1kobnaOzxWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V3AD7U8tzxQ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}